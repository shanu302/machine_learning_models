{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#implementing a sentence classfier using cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import random\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#download the data if not already available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maybe_download(url,name):\n",
    "    filename, _ = urlretrieve(url,os.getcwd() + name)\n",
    "    return filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = maybe_download('http://cogcomp.org/Data/QA/QC/TREC_10.label','/trec_10.label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sent_length = 0\n",
    "\n",
    "def read_data(filename):\n",
    "    global max_sent_length\n",
    "    \n",
    "    questions = []\n",
    "    labels = []\n",
    "    \n",
    "    with open(filename,'r',encoding = 'latin-1') as f:\n",
    "        for row in f:\n",
    "            row_data = row.split(':')\n",
    "            \n",
    "            lab,q = row_data[0],row_data[1]\n",
    "            questions.append(q.split())\n",
    "            labels.append(lab)\n",
    "            if len(questions[-1]) > max_sent_length:\n",
    "                max_sent_length = len(questions[-1])\n",
    "    print(max_sent_length)   \n",
    "    return questions,labels\n",
    "\n",
    "            \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "# train and test set\n",
    "test_questions,test_labels = read_data(\"trec_10.label\")\n",
    "train_questions,train_labels = read_data(\"file_1000.label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now pad shorter sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train question padded\n"
     ]
    }
   ],
   "source": [
    "for qi,que in enumerate(train_questions):\n",
    "    for _ in range(max_sent_length - len(que)):\n",
    "        que.append(\"PAD\")\n",
    "    train_questions[qi] = que\n",
    "print(\"train question padded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test questions padded\n"
     ]
    }
   ],
   "source": [
    "#now pad test Questions\n",
    "for qi,que in enumerate(test_questions):\n",
    "    for _ in range(max_sent_length - len(que)):\n",
    "        que.append(\"PAD\")\n",
    "    test_questions[qi] = que\n",
    "print(\"test questions padded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(questions):\n",
    "    words = []\n",
    "    data_list = []\n",
    "    count = []\n",
    "    for d in questions:\n",
    "        words.extend(d)\n",
    "    count.extend(collections.Counter(words).most_common())\n",
    "    \n",
    "    dictionary = dict()\n",
    "    for word,_ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    for d in questions:\n",
    "        data = list()\n",
    "        for word in d:\n",
    "            index = dictionary[word]\n",
    "            data.append(index)\n",
    "        data_list.append(data)\n",
    "        \n",
    "    reverse_dictionary = dict(zip(dictionary.values() , dictionary.keys()))\n",
    "    \n",
    "    return data_list,count,dictionary,reverse_dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_questions = list(train_questions)\n",
    "all_questions.extend(test_questions)\n",
    "data_list,count,dictionary,reverse_dictionary = build_dataset(all_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "sent_length = max_sent_length\n",
    "num_classes = 6\n",
    "all_labels = ['NUM','LOC','HUM','DESC','ENTY','ABBR']\n",
    "vocabulary_size = len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3548\n"
     ]
    }
   ],
   "source": [
    "print(vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample batch label\n",
      "[3 4 3 4 5 2 2 2 3 2 0 3 2 2 4 1]\n",
      "[3 0 3 3 0 4 2 3 3 4 2 1 4 1 5 4]\n",
      "Shape of sample batch size : (16,33,3548) \n",
      "shape of sample label size : (16,6)\n"
     ]
    }
   ],
   "source": [
    "class BatchGenerator(object):\n",
    "    \n",
    "    def __init__(self,batch_size,questions,labels):\n",
    "        self.questions = questions\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.text_size = len(questions)\n",
    "        self.data_index = 0\n",
    "        \n",
    "    def generate_batch(self):\n",
    "        \n",
    "        global sent_length,num_classes\n",
    "        global dictionary,all_labels\n",
    "        \n",
    "        inputs = np.zeros((self.batch_size,sent_length,vocabulary_size),dtype = np.float32)\n",
    "        label_op = np.zeros((self.batch_size,num_classes),dtype = np.float32)\n",
    "        \n",
    "        if self.data_index + self.batch_size > self.text_size:\n",
    "            self.data_index = 0\n",
    "        for qi, que in enumerate(self.questions[self.data_index:self.data_index + self.batch_size]):\n",
    "            \n",
    "            for wi,word in enumerate(que):\n",
    "                inputs[qi,wi,dictionary[word]] = 1.0\n",
    "            label_op[qi,all_labels.index(self.labels[self.data_index + qi])] = 1.0\n",
    "        self.data_index = (self.data_index + self.batch_size)%self.text_size\n",
    "        return inputs,label_op\n",
    "    \n",
    "    def return_index(self):\n",
    "        return self.data_index\n",
    "    \n",
    "            \n",
    "sample_gen = BatchGenerator(batch_size,train_questions,train_labels)\n",
    "\n",
    "sample_batch_inputs,sample_batch_label = sample_gen.generate_batch()\n",
    "sample_batch_inputs_2,sample_batch_label_2 = sample_gen.generate_batch()\n",
    "\n",
    "print(\"sample batch label\")\n",
    "print(np.argmax(sample_batch_label,axis=1))\n",
    "print(np.argmax(sample_batch_label_2,axis = 1))\n",
    "print(\"Shape of sample batch size : (%d,%d,%d) \" % (sample_batch_inputs.shape))\n",
    "print(\"shape of sample label size : (%d,%d)\" % (sample_batch_label.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining hyperparaaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "filter_size = [3,5,7]\n",
    "\n",
    "sample_input = tf.placeholder(shape=[batch_size,sent_length,vocabulary_size],dtype = tf.float32,name = \"sentence_input\")\n",
    "sample_label = tf.placeholder(shape=[batch_size,num_classes],dtype = tf.float32,name = \"sentence_label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = tf.Variable(tf.truncated_normal([filter_size[0],vocabulary_size,1],stddev = 0.02, dtype = tf.float32),name = \"weight_1\")\n",
    "b1 = tf.Variable(tf.random_uniform([1], 0,0.01, dtype = tf.float32),name = \"bias_1\")\n",
    "\n",
    "w2 = tf.Variable(tf.truncated_normal([filter_size[1],vocabulary_size,1],stddev = 0.02,dtype = tf.float32), name = \"weight_2\")\n",
    "b2 = tf.Variable(tf.random_uniform([1],0,0.01,dtype = tf.float32), name = \"bias_2\")\n",
    "\n",
    "w3 = tf.Variable(tf.truncated_normal([filter_size[2],vocabulary_size,1],stddev = 0.02, dtype = tf.float32),name = \"weight_3\")\n",
    "b3 = tf.Variable(tf.random_uniform([1], 0,0.01, dtype = tf.float32),name = \"bias_3\")\n",
    "\n",
    "w_fc1 = tf.Variable(tf.truncated_normal([len(filter_size),num_classes], dtype = tf.float32), name = \"weight_fulocn1\")\n",
    "b_fc1 = tf.Variable(tf.random_uniform([num_classes],0,0.01,dtype = tf.float32),name = \"bias_fulcon1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining inference of the cnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_1 = tf.nn.relu(tf.nn.conv1d(sample_input,w1,stride=1,padding = \"SAME\") + b1)\n",
    "h1_2 = tf.nn.relu(tf.nn.conv1d(sample_input,w2,stride = 1,padding= 'SAME') + b2)\n",
    "h1_3 = tf.nn.relu(tf.nn.conv1d(sample_input,w3,stride = 1,padding = \"SAME\") + b3)\n",
    "\n",
    "\n",
    "# pooling operation\n",
    "\n",
    "h2_1 = tf.reduce_max(h1_1,axis=1)\n",
    "h2_2 = tf.reduce_max(h1_2,axis = 1)\n",
    "h2_3 = tf.reduce_max(h1_3,axis = 1)\n",
    "\n",
    "h2 = tf.concat([h2_1,h2_2,h2_3], axis = 1)\n",
    "\n",
    "#calculate the fully connectd layer output(no activation)\n",
    "\n",
    "logits = tf.matmul(h2,w_fc1) + b_fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=sample_label,logits = logits))\n",
    "\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate = 0.01, momentum = 0.9).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = tf.argmax(tf.nn.softmax(logits),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#running our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(labels,preds):\n",
    "    return np.sum(np.argmax(labels,axis=1)==preds)/labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss at epoch 0 : 1.77\n",
      "train loss at epoch 1 : 1.70\n",
      "train loss at epoch 2 : 1.65\n",
      "train loss at epoch 3 : 1.56\n",
      "train loss at epoch 4 : 1.50\n",
      "mean test accuracy in epoch 4 is 48.542\n",
      "train loss at epoch 5 : 1.43\n",
      "train loss at epoch 6 : 1.36\n",
      "train loss at epoch 7 : 1.31\n",
      "train loss at epoch 8 : 1.22\n",
      "train loss at epoch 9 : 1.16\n",
      "mean test accuracy in epoch 9 is 68.750\n",
      "train loss at epoch 10 : 1.11\n",
      "train loss at epoch 11 : 1.06\n",
      "train loss at epoch 12 : 1.00\n",
      "train loss at epoch 13 : 0.96\n",
      "train loss at epoch 14 : 0.90\n",
      "mean test accuracy in epoch 14 is 76.250\n",
      "train loss at epoch 15 : 0.84\n",
      "train loss at epoch 16 : 0.83\n",
      "train loss at epoch 17 : 0.75\n",
      "train loss at epoch 18 : 0.73\n",
      "train loss at epoch 19 : 0.70\n",
      "mean test accuracy in epoch 19 is 83.750\n",
      "train loss at epoch 20 : 0.65\n",
      "train loss at epoch 21 : 0.63\n",
      "train loss at epoch 22 : 0.59\n",
      "train loss at epoch 23 : 0.57\n",
      "train loss at epoch 24 : 0.52\n",
      "mean test accuracy in epoch 24 is 86.667\n",
      "train loss at epoch 25 : 0.56\n",
      "train loss at epoch 26 : 0.47\n",
      "train loss at epoch 27 : 0.50\n",
      "train loss at epoch 28 : 0.46\n",
      "train loss at epoch 29 : 0.45\n",
      "mean test accuracy in epoch 29 is 87.708\n",
      "train loss at epoch 30 : 0.43\n",
      "train loss at epoch 31 : 0.42\n",
      "train loss at epoch 32 : 0.40\n",
      "train loss at epoch 33 : 0.39\n",
      "train loss at epoch 34 : 0.37\n",
      "mean test accuracy in epoch 34 is 86.250\n",
      "train loss at epoch 35 : 0.33\n",
      "train loss at epoch 36 : 0.39\n",
      "train loss at epoch 37 : 0.32\n",
      "train loss at epoch 38 : 0.35\n",
      "train loss at epoch 39 : 0.31\n",
      "mean test accuracy in epoch 39 is 87.500\n",
      "train loss at epoch 40 : 0.31\n",
      "train loss at epoch 41 : 0.30\n",
      "train loss at epoch 42 : 0.31\n",
      "train loss at epoch 43 : 0.29\n",
      "train loss at epoch 44 : 0.28\n",
      "mean test accuracy in epoch 44 is 87.500\n",
      "train loss at epoch 45 : 0.27\n",
      "train loss at epoch 46 : 0.24\n",
      "train loss at epoch 47 : 0.29\n",
      "train loss at epoch 48 : 0.24\n",
      "train loss at epoch 49 : 0.27\n",
      "mean test accuracy in epoch 49 is 89.167\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "num_steps = 50\n",
    "\n",
    "train_gen = BatchGenerator(batch_size,train_questions,train_labels)\n",
    "test_gen = BatchGenerator(batch_size,test_questions,test_labels)\n",
    "\n",
    "test_interval = 5\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for step in range(num_steps):\n",
    "        avg_loss = []\n",
    "        \n",
    "        \n",
    "        for tr_ in range((len(test_questions)//batch_size) - 1):\n",
    "            tr_input,tr_label = train_gen.generate_batch()\n",
    "            \n",
    "            l, _ = sess.run([loss,optimizer],feed_dict = {sample_input :tr_input,sample_label:tr_label})\n",
    "            avg_loss.append(l)\n",
    "        print(\"train loss at epoch %d : %.2f\" % (step,np.mean(avg_loss)))\n",
    "        \n",
    "        test_accuracy = []\n",
    "        \n",
    "        if(step+1)%test_interval ==0:\n",
    "            for ts_i in range((len(test_questions)-1)//batch_size):\n",
    "                \n",
    "                ts_input,ts_label = test_gen.generate_batch()\n",
    "                a = sess.run(predictions, feed_dict = {sample_input : ts_input,sample_label:ts_label})\n",
    "                test_accuracy.append(accuracy(ts_label,a))\n",
    "                \n",
    "            print(\"mean test accuracy in epoch %d is %.3f\" % (step,np.mean(test_accuracy)*100.0))\n",
    "\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
